import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:audioplayers/audioplayers.dart';

class ElevenLabsTTSService {
  static final ElevenLabsTTSService _instance = ElevenLabsTTSService._internal();
  factory ElevenLabsTTSService() => _instance;
  ElevenLabsTTSService._internal();

  // ElevenLabs API Configuration
  static const String _apiKey = 'sk_4ed86b6ddfe1060a3789a795cf49875c5bdf47c7a51e826b';
  static const String _baseUrl = 'https://api.elevenlabs.io/v1';
  static const String _model = 'eleven_multilingual_v2';
  
  // Voice IDs for different languages and styles - Updated for Arya
  static const String _hindiVoiceId = 'EXAVITQu4vr4xnSDxMaL'; // Bella - Female Hindi voice
  static const String _aryaVoiceId = 'AZnzlk1XvdvUeBnXmlld'; // Primary Arya voice
  
  late AudioPlayer _audioPlayer;
  bool _isInitialized = false;
  bool _isSpeaking = false;
  bool _isEnabled = true;
  String _currentLanguage = 'en-US';

  // Getters
  bool get isInitialized => _isInitialized;
  bool get isSpeaking => _isSpeaking;
  bool get isEnabled => _isEnabled;
  String get currentLanguage => _currentLanguage;

  // Initialize ElevenLabs TTS service
  Future<void> initialize() async {
    if (_isInitialized) return;

    try {
      _audioPlayer = AudioPlayer();
      
      // Configure audio player for better compatibility and volume
      await _audioPlayer.setReleaseMode(ReleaseMode.release);
      await _audioPlayer.setPlayerMode(PlayerMode.mediaPlayer);
      await _audioPlayer.setVolume(1.0); // Set maximum volume
      
      // Set up audio player event handlers
      _audioPlayer.onPlayerStateChanged.listen((PlayerState state) {
        switch (state) {
          case PlayerState.playing:
            _isSpeaking = true;
            if (kDebugMode) print('üé§ Arya (ElevenLabs) started speaking');
            break;
          case PlayerState.completed:
          case PlayerState.stopped:
            _isSpeaking = false;
            if (kDebugMode) print('üé§ Arya (ElevenLabs) finished speaking');
            break;
          case PlayerState.paused:
            if (kDebugMode) print('üé§ Arya (ElevenLabs) paused');
            break;
          case PlayerState.disposed:
            _isSpeaking = false;
            if (kDebugMode) print('üé§ Arya (ElevenLabs) disposed');
            break;
        }
      });

      _audioPlayer.onPlayerComplete.listen((_) {
        _isSpeaking = false;
        if (kDebugMode) print('üé§ Arya (ElevenLabs) playback completed');
      });

      _isInitialized = true;
      if (kDebugMode) print('‚úÖ ElevenLabs TTS initialized successfully');
    } catch (e) {
      if (kDebugMode) print('‚ùå Failed to initialize ElevenLabs TTS: $e');
      _isInitialized = false;
    }
  }

  // Set language for voice selection
  Future<void> setLanguage(String language) async {
    _currentLanguage = language;
    if (kDebugMode) print('üé§ ElevenLabs language set to: $language');
  }

  // Get voice ID based on current language
  String _getVoiceId() {
    switch (_currentLanguage) {
      case 'hi-IN':
        return _hindiVoiceId;
      case 'en-US':
      case 'en-GB':
      case 'en-AU':
      default:
        return _aryaVoiceId; // Use Arya's dedicated voice
    }
  }

  // Core speak method that handles ElevenLabs TTS
  Future<void> speak(String text) async {
    if (!_isInitialized || !_isEnabled || text.trim().isEmpty) {
      if (kDebugMode) print('üé§ ElevenLabs TTS: Cannot speak - initialized: $_isInitialized, enabled: $_isEnabled, text empty: ${text.trim().isEmpty}');
      return;
    }

    try {
      // Stop any current playback
      if (_isSpeaking) {
        await _audioPlayer.stop();
        await Future.delayed(const Duration(milliseconds: 300));
      }

      // Ensure volume is at maximum
      await _audioPlayer.setVolume(1.0);

      if (kDebugMode) print('üé§ ElevenLabs TTS: Generating speech for text (${text.length} chars): "${text.substring(0, text.length > 50 ? 50 : text.length)}..."');

      // Generate audio from ElevenLabs API
      final audioData = await _generateSpeech(text);
      
      if (audioData != null && audioData.isNotEmpty) {
        if (kDebugMode) print('üé§ ElevenLabs TTS: Audio data generated successfully (${audioData.length} bytes)');
        // Play the generated audio
        await _playAudioData(audioData);
      } else {
        if (kDebugMode) print('‚ùå ElevenLabs TTS: Failed to generate audio data or empty response');
        // Fallback to Flutter TTS if ElevenLabs fails
        throw Exception('ElevenLabs audio generation failed');
      }
    } catch (e) {
      if (kDebugMode) print('‚ùå ElevenLabs TTS speak error: $e');
      // Don't rethrow - let the calling service handle fallback
    }
  }

  // Generate audio using ElevenLabs API
  Future<Uint8List?> _generateSpeech(String text) async {
    try {
      final voiceId = _getVoiceId();
      final url = '$_baseUrl/text-to-speech/$voiceId';
      
      final headers = {
        'Accept': 'audio/mpeg',
        'Content-Type': 'application/json',
        'xi-api-key': _apiKey,
      };

      final body = jsonEncode({
        'text': text,
        'model_id': _model,
        'voice_settings': {
          'stability': 0.6,
          'similarity_boost': 0.8,
          'style': 0.2,
          'use_speaker_boost': true,
        },
      });

      if (kDebugMode) print('üé§ Making ElevenLabs API request...');
      
      final response = await http.post(
        Uri.parse(url),
        headers: headers,
        body: body,
      );

      if (response.statusCode == 200) {
        if (kDebugMode) print('‚úÖ ElevenLabs API request successful (${response.bodyBytes.length} bytes)');
        if (response.bodyBytes.isEmpty) {
          if (kDebugMode) print('‚ùå ElevenLabs API returned empty audio data');
          return null;
        }
        return response.bodyBytes;
      } else {
        if (kDebugMode) print('‚ùå ElevenLabs API error: ${response.statusCode} - ${response.body}');
        return null;
      }
    } catch (e) {
      if (kDebugMode) print('‚ùå ElevenLabs API request failed: $e');
      return null;
    }
  }

  // Play audio data using AudioPlayer
  Future<void> _playAudioData(Uint8List audioData) async {
    try {
      if (kDebugMode) print('üé§ Audio data size: ${audioData.length} bytes');
      
      // Try BytesSource first (most reliable for audio data)
      try {
        if (kDebugMode) print('üé§ Trying BytesSource playback...');
        await _audioPlayer.play(BytesSource(audioData));
        if (kDebugMode) print('‚úÖ BytesSource playback successful');
        return;
      } catch (bytesError) {
        if (kDebugMode) print('‚ùå BytesSource failed: $bytesError');
      }
      
      // Fallback: Try platform-specific approaches
      await _tryPlatformSpecificPlayback(audioData);
    } catch (e) {
      if (kDebugMode) print('‚ùå Error in audio playback: $e');
      rethrow;
    }
  }

  // Platform-specific audio playback fallbacks
  Future<void> _tryPlatformSpecificPlayback(Uint8List audioData) async {
    try {
      if (kDebugMode) print('üé§ Trying platform-specific audio playback...');
      
      // Try base64 data URL approach
      try {
        if (kDebugMode) print('üé§ Converting audio data to base64 URL...');
        final base64Audio = base64Encode(audioData);
        final dataUrl = 'data:audio/mpeg;base64,$base64Audio';
        
        if (kDebugMode) print('üé§ Playing audio from data URL...');
        await _audioPlayer.play(UrlSource(dataUrl));
        if (kDebugMode) print('‚úÖ Data URL playback successful');
        return;
      } catch (dataUrlError) {
        if (kDebugMode) print('‚ùå Data URL failed: $dataUrlError');
      }
      
      // Try creating temporary file with proper path
      try {
        final tempDir = Directory.systemTemp;
        final fileName = 'arya_${DateTime.now().millisecondsSinceEpoch}.mp3';
        final file = File('${tempDir.path}/$fileName');
        
        await file.writeAsBytes(audioData);
        
        if (kDebugMode) print('üé§ Playing from temp file: ${file.path}');
        
        await _audioPlayer.play(DeviceFileSource(file.path));
        
        // Clean up after delay
        Future.delayed(const Duration(seconds: 30), () {
          try {
            if (file.existsSync()) {
              file.deleteSync();
              if (kDebugMode) print('üóëÔ∏è Cleaned up audio file');
            }
          } catch (cleanupError) {
            if (kDebugMode) print('‚ö†Ô∏è Cleanup error: $cleanupError');
          }
        });
        
        if (kDebugMode) print('‚úÖ File-based playback successful');
        return;
      } catch (fileError) {
        if (kDebugMode) print('‚ùå File-based playback failed: $fileError');
      }
      
      // Final fallback: Use Flutter TTS
      if (kDebugMode) print('üîÑ All audio methods failed, falling back to Flutter TTS');
      throw Exception('All audio playback methods failed');
      
    } catch (e) {
      if (kDebugMode) print('‚ùå All platform-specific playback methods failed: $e');
      rethrow;
    }
  }


  // Arya speaks the introduction message
  Future<void> speakIntroduction() async {
    String message;
    if (_currentLanguage == 'hi-IN') {
      message = "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§Ü‡§∞‡•ç‡§Ø‡§æ ‡§π‡•Ç‡§Å, ‡§Ü‡§™‡§ï‡•Ä AI ‡§á‡§Ç‡§ü‡§∞‡§µ‡•ç‡§Ø‡•Ç‡§Ö‡§∞‡•§ ‡§Æ‡•Å‡§ù‡•á ‡§ú‡§ó‡§¶‡•Ä‡§∂ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§§‡§æ‡§ï‡§ø ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•á ‡§á‡§Ç‡§ü‡§∞‡§µ‡•ç‡§Ø‡•Ç ‡§ï‡•å‡§∂‡§≤ ‡§ï‡§æ ‡§Ö‡§≠‡•ç‡§Ø‡§æ‡§∏ ‡§ï‡§∞ ‡§∏‡§ï‡•á‡§Ç ‡§î‡§∞ ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞ ‡§∏‡§ï‡•á‡§Ç‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•á ‡§ö‡•Å‡§®‡•á ‡§ó‡§è ‡§ú‡•â‡§¨ ‡§∞‡•ã‡§≤ ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•Ç‡§Ç‡§ó‡•Ä ‡§î‡§∞ ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§´‡•Ä‡§°‡§¨‡•à‡§ï ‡§¶‡•Ç‡§Ç‡§ó‡•Ä‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§Æ‡•á‡§∞‡•á ‡§∏‡§æ‡§• ‡§Ö‡§™‡§®‡•Ä ‡§á‡§Ç‡§ü‡§∞‡§µ‡•ç‡§Ø‡•Ç ‡§Ø‡§æ‡§§‡•ç‡§∞‡§æ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à‡§Ç?";
    } else {
      message = "Hello! I am Arya, your AI interviewer. I was developed by Jagdish to help you practice and improve your interview skills. I will ask you questions based on your chosen job role and provide detailed feedback to help you grow. Are you ready to begin your interview journey with me?";
    }
    await speak(message);
  }

  // Arya speaks a question
  Future<void> speakQuestion(String question) async {
    String message;
    if (_currentLanguage == 'hi-IN') {
      message = "‡§Ø‡§π‡§æ‡§Å ‡§Ü‡§™‡§ï‡§æ ‡§Ö‡§ó‡§≤‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§π‡•à: $question‡•§ ‡§∏‡•ã‡§ö‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§™‡§®‡§æ ‡§∏‡§Æ‡§Ø ‡§≤‡•á‡§Ç ‡§î‡§∞ ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç‡•§";
    } else {
      message = "Here's your next question: $question. Take your time to think and provide a comprehensive answer.";
    }
    await speak(message);
  }

  // Arya speaks feedback summary
  Future<void> speakFeedback(String feedback, double score) async {
    String scoreComment = '';
    if (_currentLanguage == 'hi-IN') {
      if (score >= 8.0) {
        scoreComment = '‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü ‡§ï‡§æ‡§Æ!';
      } else if (score >= 6.0) {
        scoreComment = '‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ!';
      } else if (score >= 4.0) {
        scoreComment = '‡§¨‡•Å‡§∞‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡•Ä ‡§ó‡•Å‡§Ç‡§ú‡§æ‡§á‡§∂ ‡§π‡•à‡•§';
      } else {
        scoreComment = '‡§Ü‡§á‡§è ‡§á‡§∏‡•á ‡§Æ‡§ø‡§≤‡§ï‡§∞ ‡§¨‡•á‡§π‡§§‡§∞ ‡§¨‡§®‡§æ‡§§‡•á ‡§π‡•à‡§Ç‡•§';
      }
    } else {
      if (score >= 8.0) {
        scoreComment = 'Excellent work!';
      } else if (score >= 6.0) {
        scoreComment = 'Good job!';
      } else if (score >= 4.0) {
        scoreComment = 'Not bad, but there\'s room for improvement.';
      } else {
        scoreComment = 'Let\'s work on improving this together.';
      }
    }

    String message;
    if (_currentLanguage == 'hi-IN') {
      message = "$scoreComment ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§ï‡•ã‡§∞ 10 ‡§Æ‡•á‡§Ç ‡§∏‡•á ${score.toStringAsFixed(1)} ‡§π‡•à‡•§ $feedback";
    } else {
      message = "$scoreComment You scored ${score.toStringAsFixed(1)} out of 10. $feedback";
    }
    await speak(message);
  }

  // Arya speaks the final interview summary
  Future<void> speakSummary(String summary, double averageScore) async {
    String congratulations = '';
    if (_currentLanguage == 'hi-IN') {
      if (averageScore >= 8.0) {
        congratulations = '‡§¨‡§ß‡§æ‡§à ‡§π‡•ã! ‡§Ü‡§™‡§®‡•á ‡§á‡§∏ ‡§á‡§Ç‡§ü‡§∞‡§µ‡•ç‡§Ø‡•Ç ‡§Æ‡•á‡§Ç ‡§Ö‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§';
      } else if (averageScore >= 6.0) {
        congratulations = '‡§¨‡§π‡•Å‡§§ ‡§¨‡§¢‡§º‡§ø‡§Ø‡§æ! ‡§Ü‡§™‡§®‡•á ‡§Ö‡§ö‡•ç‡§õ‡•á ‡§á‡§Ç‡§ü‡§∞‡§µ‡•ç‡§Ø‡•Ç ‡§ï‡•å‡§∂‡§≤ ‡§¶‡§ø‡§ñ‡§æ‡§è ‡§π‡•à‡§Ç‡•§';
      } else {
        congratulations = '‡§á‡§Ç‡§ü‡§∞‡§µ‡•ç‡§Ø‡•Ç ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§ ‡§Ø‡§æ‡§¶ ‡§∞‡§ñ‡•á‡§Ç, ‡§Ö‡§≠‡•ç‡§Ø‡§æ‡§∏ ‡§∏‡•á ‡§π‡•Ä ‡§∏‡§ø‡§¶‡•ç‡§ß‡§ø ‡§Æ‡§ø‡§≤‡§§‡•Ä ‡§π‡•à!';
      }
    } else {
      if (averageScore >= 8.0) {
        congratulations = 'Congratulations! You performed exceptionally well in this interview.';
      } else if (averageScore >= 6.0) {
        congratulations = 'Well done! You showed good interview skills.';
      } else {
        congratulations = 'Thank you for completing the interview. Remember, practice makes perfect!';
      }
    }

    String message;
    if (_currentLanguage == 'hi-IN') {
      message = "$congratulations ‡§Ü‡§™‡§ï‡§æ ‡§∏‡§Æ‡§ó‡•ç‡§∞ ‡§∏‡•ç‡§ï‡•ã‡§∞ 10 ‡§Æ‡•á‡§Ç ‡§∏‡•á ${averageScore.toStringAsFixed(1)} ‡§π‡•à‡•§ $summary";
    } else {
      message = "$congratulations Your overall score is ${averageScore.toStringAsFixed(1)} out of 10. $summary";
    }
    await speak(message);
  }

  // Stop Arya from speaking
  Future<void> stop() async {
    if (!_isInitialized) return;
    
    try {
      await _audioPlayer.stop();
      _isSpeaking = false;
      if (kDebugMode) print('üé§ Arya (ElevenLabs) stopped speaking');
    } catch (e) {
      if (kDebugMode) print('‚ùå Error stopping ElevenLabs TTS: $e');
    }
  }

  // Pause Arya's speech
  Future<void> pause() async {
    if (!_isInitialized || !_isSpeaking) return;
    
    try {
      await _audioPlayer.pause();
      if (kDebugMode) print('üé§ Arya (ElevenLabs) speech paused');
    } catch (e) {
      if (kDebugMode) print('‚ùå Error pausing ElevenLabs TTS: $e');
    }
  }

  // Resume Arya's speech
  Future<void> resume() async {
    if (!_isInitialized) return;
    
    try {
      await _audioPlayer.resume();
      if (kDebugMode) print('üé§ Arya (ElevenLabs) speech resumed');
    } catch (e) {
      if (kDebugMode) print('‚ùå Error resuming ElevenLabs TTS: $e');
    }
  }

  // Enable/disable Arya's voice
  void setEnabled(bool enabled) {
    _isEnabled = enabled;
    if (!enabled && _isSpeaking) {
      stop();
    }
    if (kDebugMode) print('üé§ Arya (ElevenLabs) TTS ${enabled ? 'enabled' : 'disabled'}');
  }

  // Dispose resources
  Future<void> dispose() async {
    if (_isInitialized) {
      await stop();
      await _audioPlayer.dispose();
      _isInitialized = false;
      if (kDebugMode) print('üé§ Arya (ElevenLabs) TTS disposed');
    }
  }
}
